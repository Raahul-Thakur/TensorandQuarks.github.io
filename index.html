<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home | Tensors & Quarks</title>
    <link rel="stylesheet" href="/tensorandquarks.github.io/assets/style.css" />
    <script>
      // Dark mode script
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }

      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Home | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Home" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://raahul-thakur.github.io/tensorandquarks.github.io/" />
<meta property="og:url" content="https://raahul-thakur.github.io/tensorandquarks.github.io/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Home","name":"Tensors &amp; Quarks","url":"https://raahul-thakur.github.io/tensorandquarks.github.io/"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/tensorandquarks.github.io/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/tensorandquarks.github.io/">Home</a>
          <a href="/tensorandquarks.github.io/about.html">About</a>
          <button onclick="toggleDarkMode()">üåì</button>
        </nav>
      </div>
    </header>
    <main class="container">
      <div class="hero">
  <h1>Welcome to Tensors &amp; Quarks</h1>
  <p>Exploring the cosmos of Physics &amp; the depths of Machine Learning.</p>
</div>

<h2>Latest Posts</h2>

<ul class="post-list">
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html">Seal-Tools: Teaching AI Agents to Use Tools Like Developers</a></h2>

      <p class="post-meta">
        November 21, 2024
        
           <span class="inline-tag">ML</span>
        
      </p>

      <p><h1 id="teaching-ai-to-use-tools--the-right-way">Teaching AI to Use Tools ‚Äî The Right Way</h1>
<p><strong>A Deep Dive into Seal-Tools: The Dataset That Makes LLMs Smarter Agents</strong></p>

<p>Imagine asking your AI assistant to ‚Äúbook a flight to Paris, then schedule a taxi to the airport and convert the final bill to Euros.‚Äù Sounds simple, right? In reality, for most AI models, this isn‚Äôt just 
hard ‚Äî it‚Äôs nearly impossible to get right without human babysitting.</p>

<p>That‚Äôs because tool use, chaining functions, and executing multi-step operations <strong>requires structured reasoning</strong>, parameter handling, and format control ‚Äî things even the smartest LLMs struggle with today.</p>

<p>This is the exact problem that the new research paper <a href="https://arxiv.org/abs/2405.08355">Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark</a> seeks to solve. If you‚Äôre 
interested in building reliable AI agents, this paper is a must-read ‚Äî and this post will walk you through why.</p>

<hr />

<h2 id="why-tool-use-is-the-future-of-ai">Why Tool Use Is the Future of AI</h2>

<p>Large Language Models like GPT-4 and Claude have sparked a revolution in natural language understanding. But the next frontier is not just understanding ‚Äî it‚Äôs <strong>action</strong>.</p>

<blockquote>
  <p>Tools are the hands of the AI. Without them, a model can speak, but it cannot do.</p>
</blockquote>

<p>An AI that writes a travel plan is helpful. But one that calls an API to book the trip, checks the weather, converts currencies, and sends you a summary ‚Äî now that‚Äôs a <strong>true agent</strong>.</p>

<p>This kind of reasoning requires a model to:</p>

<ul>
  <li><strong>Choose the right tool for the job</strong></li>
  <li><strong>Fill in the correct parameters</strong></li>
  <li><strong>Follow strict output formats</strong> (e.g., JSON or function calls)</li>
  <li><strong>Chain tools across multiple steps</strong></li>
</ul>

<p>Unfortunately, even the most powerful models today fall short. That‚Äôs where <strong>Seal-Tools</strong> steps in.</p>

<hr />

<h2 id="what-is-seal-tools">What Is Seal-Tools?</h2>

<p>Seal-Tools is a <strong>large-scale, structured dataset</strong> built to train and evaluate LLMs in tool-use scenarios. The core idea is to <strong>teach AI how to call tools just like developers use APIs</strong> ‚Äî only in natural 
language.</p>

<p>It includes:</p>

<ul>
  <li>1,042 unique tools across diverse domains</li>
  <li>Over 100,000 tool-use instances generated using <em>Self-Instruct</em></li>
  <li>Examples of multi-tool, nested, and chained operations</li>
  <li>Strict JSON-format outputs for consistency and automation</li>
</ul>

<p>Each tool is described just like a real-world API:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"currency_converter"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"description"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Convert a value between currencies."</span><span class="p">,</span><span class="w">
  </span><span class="nl">"parameters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"from_currency"</span><span class="p">:</span><span class="w"> </span><span class="s2">"USD"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"to_currency"</span><span class="p">:</span><span class="w"> </span><span class="s2">"EUR"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"amount"</span><span class="p">:</span><span class="w"> </span><span class="s2">"100.0"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"required"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"from_currency"</span><span class="p">,</span><span class="w"> </span><span class="s2">"to_currency"</span><span class="p">,</span><span class="w"> </span><span class="s2">"amount"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>And each <strong>task instance</strong> simulates a realistic scenario:</p>

<blockquote>
  <p>‚ÄúConvert 100 USD to EUR, and then use the result to calculate VAT in France.‚Äù</p>
</blockquote>

<hr />

<h2 id="how-it-was-built--the-self-instruct-pipeline">How It Was Built ‚Äî The Self-Instruct Pipeline</h2>

<p>What‚Äôs genius about Seal-Tools is that it uses LLMs <strong>to generate the dataset themselves</strong> ‚Äî but with checks, balances, and curation.</p>

<p>Here‚Äôs the step-by-step pipeline:</p>

<ul>
  <li><strong>Field Generation</strong> ‚Äì Domains like finance, health, or travel are first generated.</li>
  <li><strong>Tool Design</strong> ‚Äì Each field includes several tool descriptions.</li>
  <li><strong>Instance Generation</strong> ‚Äì Each tool gets basic and complex tool-usage tasks.</li>
  <li><strong>Validation</strong> ‚Äì JSON output is validated for structure and semantic consistency.</li>
</ul>

<p>This lets researchers <strong>generate massive datasets quickly</strong> while maintaining realism and structure.</p>

<hr />

<h2 id="evaluation-metrics-that-actually-matter">Evaluation: Metrics That Actually Matter</h2>

<p>Seal-Tools introduces three targeted evaluation metrics:</p>

<ol>
  <li><strong>Format Accuracy</strong> ‚Äì Can the model generate valid JSON or function calls?</li>
  <li><strong>Tool Selection Accuracy</strong> ‚Äì Did it choose the correct tools for the task?</li>
  <li><strong>Parameter Filling Accuracy</strong> ‚Äì Did it supply correct and complete values?</li>
</ol>

<p>These are <strong>objective and automatable</strong>, unlike vague scores used in standard NLP evaluations.</p>

<hr />

<h2 id="what-did-the-experiments-reveal">What Did the Experiments Reveal?</h2>

<p>Models tested in the paper include:</p>

<ul>
  <li>GPT-3.5 and GPT-4</li>
  <li>Claude 2</li>
  <li>LLaMA2-7B, Vicuna, Mistral-7B</li>
  <li>A fine-tuned LLaMA2 trained on Seal-Tools</li>
</ul>

<p><strong>Key takeaways</strong>:</p>

<ul>
  <li>GPT-4 leads the pack, but still struggles with nested or chained tool usage.</li>
  <li>Open-source models have significant limitations out-of-the-box.</li>
  <li>Fine-tuning on Seal-Tools improves tool performance by <strong>15‚Äì20%</strong>.</li>
</ul>

<blockquote>
  <p>Even top models are not great tool users‚Ä¶ <em>yet</em>.</p>
</blockquote>

<hr />

<h2 id="how-seal-tools-stands-out">How Seal-Tools Stands Out</h2>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>ToolBench</th>
      <th>API-Bank</th>
      <th>ToolAlpaca</th>
      <th><strong>Seal-Tools</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Number of Tools</td>
      <td>~300</td>
      <td>~100</td>
      <td>~50</td>
      <td><strong>1,042</strong></td>
    </tr>
    <tr>
      <td>Multi-Tool Support</td>
      <td>‚ùå</td>
      <td>‚ùå</td>
      <td>Partial</td>
      <td>‚úÖ</td>
    </tr>
    <tr>
      <td>Nested Calls</td>
      <td>‚ùå</td>
      <td>‚ùå</td>
      <td>‚ùå</td>
      <td>‚úÖ</td>
    </tr>
    <tr>
      <td>Format Consistency</td>
      <td>YAML</td>
      <td>Loose</td>
      <td>JSON-ish</td>
      <td><strong>Strict JSON</strong></td>
    </tr>
    <tr>
      <td>Auto-Evaluation</td>
      <td>‚ùå</td>
      <td>‚ùå</td>
      <td>‚ùå</td>
      <td>‚úÖ</td>
    </tr>
  </tbody>
</table>

<p><strong>Seal-Tools</strong> is <em>bigger, more complex, and better structured</em> than any other tool-using dataset available.</p>

<hr />

<h2 id="why-this-matters-for-agentic-ai">Why This Matters for Agentic AI</h2>

<p>We‚Äôre entering an era of <strong>agentic computing</strong>, where LLMs are expected to plan, decide, and act on our behalf.</p>

<p>For this to work, models must:</p>

<ul>
  <li>Understand tool specifications</li>
  <li>Format structured calls</li>
  <li>Handle edge cases and data dependencies</li>
  <li>Chain multiple tools together intelligently</li>
</ul>

<p><strong>Seal-Tools is the training ground for this future.</strong> It‚Äôs more than a dataset ‚Äî it‚Äôs a <em>curriculum</em> for teaching LLMs real-world behavior.</p>

<hr />

<h2 id="links--resources">Links &amp; Resources</h2>

<ul>
  <li>Read the paper: <a href="https://arxiv.org/abs/2405.08355">arXiv:2405.08355</a></li>
  <li>Explore the GitHub repo: <a href="https://github.com/fairyshine/Seal-Tools">github.com/fairyshine/Seal-Tools</a></li>
  <li>View evaluation &amp; fine-tuning: <a href="https://github.com/fairyshine/Seal-Tools/tree/main/evaluation">evaluation scripts</a></li>
</ul>

<hr />

<h2 id="final-thoughts">Final Thoughts</h2>

<p><strong>Seal-Tools</strong> offers a major step forward in developing LLMs that go beyond chatting and start executing real tasks. It‚Äôs built on the idea that agents must not just <em>talk</em>, but <em>do</em> ‚Äî and 
gives us the tools to train them accordingly.</p>

<p>Whether you‚Äôre building autonomous agents, developing smart assistants, or researching LLM capabilities, <strong>Seal-Tools should be part of your stack</strong>.</p>

<blockquote>
  <p>With this dataset, we‚Äôre not just teaching AI how to use tools ‚Äî<br />
we‚Äôre teaching it how to <strong>think in actions</strong>.</p>
</blockquote>

</p>

      <a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/11/14/tensors.html">What Are Tensors?</a></h2>

      <p class="post-meta">
        November 14, 2024
        
           <span class="inline-tag">MLAstrophysics</span>
        
      </p>

      <p><h1 id="what-are-tensors">What Are Tensors?</h1>

<p>Tensors are fundamental mathematical objects that appear across various domains such as physics, computer science, and engineering. At their core, tensors are multi-dimensional arrays that generalize the 
concepts of scalars (single numbers), vectors (one-dimensional arrays), and matrices (two-dimensional arrays). Unlike simple arrays, tensors are not just containers of numbers‚Äîthey come with transformation 
rules that allow them to describe physical phenomena in a way that remains consistent across coordinate systems.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/11/14/tensors.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/11/07/React.html">From ‚ÄúWhy‚Äù to ‚ÄúHow‚Äù: ReAct‚Äôs Unified Reasoning-Acting Paradigm</a></h2>

      <p class="post-meta">
        November 7, 2024
        
           <span class="inline-tag">ML</span>
        
      </p>

      <p><h1 id="from-why-to-how-reacts-unified-reasoning-acting-paradigm">From ‚ÄúWhy‚Äù to ‚ÄúHow‚Äù: ReAct‚Äôs Unified Reasoning-Acting Paradigm</h1>

<p>Large language models (LLMs) have reshaped natural language processing by demonstrating impressive capabilities in text generation, summarization, and translation. Yet, as powerful as they are, 
these models often struggle when asked to perform complex, multi-step tasks that require deliberate planning and interaction with external information sources. Traditional chain-of-thought (CoT) 
prompting enables LLMs to articulate intermediate reasoning steps, but it remains confined to the model‚Äôs internal knowledge and inference capabilities. Conversely, action-based approaches have allowed 
models to execute external operations‚Äîsuch as querying an API or navigating an environment‚Äîbut lack explicit internal reasoning, leading to unexplainable or brittle behavior. The ReAct framework addresses 
this gap by synergizing reasoning and acting in a unified prompt-based paradigm that interleaves ‚Äúthoughts‚Äù and ‚Äúactions‚Äù to solve complex tasks more effectively and transparently.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/11/07/React.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html">From Facts to Insight: Bridging the Compositionality Gap in Language Models</a></h2>

      <p class="post-meta">
        October 31, 2024
        
           <span class="inline-tag">ML</span>
        
      </p>

      <p><h1 id="from-facts-to-insight-bridging-the-compositionality-gap-in-language-models">From Facts to Insight: Bridging the Compositionality Gap in Language Models</h1>

<p>Large language models (LLMs) such as GPT-3 have transformed natural language understanding by memorizing vast amounts of text. Yet, when faced with questions that require <strong>combining</strong> multiple pieces 
of knowledge‚Äîso-called <em>compositional reasoning</em>‚Äîeven the biggest models stumble. In their paper <em>Measuring and Narrowing the Compositionality Gap in Language Models</em>, Press et al. introduce a new metric
for this shortfall, show that it persists despite model scale, and propose practical prompting techniques to close it.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/10/24/LoRA.html">LoRA: A Breakthrough in Efficient Fine-Tuning of Large Language Models</a></h2>

      <p class="post-meta">
        October 24, 2024
        
           <span class="inline-tag">ML</span>
        
      </p>

      <p><h1 id="lora-a-breakthrough-in-efficient-fine-tuning-of-large-language-models">LoRA: A Breakthrough in Efficient Fine-Tuning of Large Language Models</h1>

<p>As large language models (LLMs) like GPT-3, LLaMA, and BERT continue to grow in size and influence, one challenge becomes increasingly apparent: while these models offer exceptional capabilities, 
<strong>adapting them for new tasks remains expensive and resource-intensive</strong>. Fine-tuning a model with billions of parameters typically requires large datasets, massive compute power, 
and hours or even days of training time ‚Äî luxuries not everyone can afford.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/10/24/LoRA.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html">Fine-Tuning Language Models: Welcome to the Nerdy Playground of LLMs</a></h2>

      <p class="post-meta">
        October 17, 2024
        
           <span class="inline-tag">ML</span>
        
      </p>

      <p><h1 id="fine-tuning-language-models-welcome-to-the-nerdy-playground-of-llms">Fine-Tuning Language Models: Welcome to the Nerdy Playground of LLMs</h1>
<p><em>From LoRA to RLHF ‚Äî and all the acronyms in between</em></p>

<p>So, you‚Äôve got your hands on a fancy pre-trained language model. Great. It‚Äôs read more text than any human ever will, speaks in Shakespearean iambic pentameter <em>and</em> Python, and can tell you the capital of Burkina Faso at 3 AM.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html" class="read-more">Read more ‚Üí</a>
    </li>
  
    <li class="post-card">
      <h2><a href="/tensorandquarks.github.io/2024/09/21/welcome.html">Welcome to Tensors &amp; Quarks</a></h2>

      <p class="post-meta">
        September 21, 2024
        
           <span class="inline-tag"></span>
        
      </p>

      <p><p>This is the first post!<br />
Here I‚Äôll share ideas in physics, AI, and their cosmic overlaps.</p>

</p>

      <a href="/tensorandquarks.github.io/2024/09/21/welcome.html" class="read-more">Read more ‚Üí</a>
    </li>
  
</ul>

    </main>
    <footer class="site-footer">
      <div class="container">
        <p>¬© 2025 Rahul Thakur ‚Ä¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
